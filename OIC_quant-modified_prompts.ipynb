{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15613,
     "status": "ok",
     "timestamp": 1692130342158,
     "user": {
      "displayName": "Simon Mayer",
      "userId": "02384340532265751587"
     },
     "user_tz": -120
    },
    "id": "SgHDpZTkCIT9",
    "outputId": "159045cf-7fce-4888-9cf7-59073fc9ce33",
    "ExecuteTime": {
     "end_time": "2023-11-23T11:29:31.503051Z",
     "start_time": "2023-11-23T11:29:31.478764Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import string\n",
    "#os.chdir('/content/drive/MyDrive/Sanjiv/IMP-OIC-Windowing')\n",
    "directory_path = 'STAR_eval/Charades'\n",
    "from gpt_ask import run_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T11:29:34.115379Z",
     "start_time": "2023-11-23T11:29:31.486281Z"
    }
   },
   "outputs": [],
   "source": [
    "main_ds = pd.read_json('STAR_eval/STAR_val.json')\n",
    "main = main_ds.loc[:, ['question_id','question','video_id','start','end','answer', 'choices']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T11:29:34.395759Z",
     "start_time": "2023-11-23T11:29:34.118033Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('STAR_eval/new_all_cured_old.csv')\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "df = df.dropna()\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T11:29:34.447717Z",
     "start_time": "2023-11-23T11:29:34.422801Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'The scene opens:\\nFrom now on man wearing shirt\\nFrom now on man wearing hat\\nFrom now on man wearing pant\\nFrom now on man wearing glove\\nFrom now on man has head\\nFrom now on man has arm\\nFrom now on man has ear\\nFrom now on man wearing glass\\nFrom now on shirt on man\\nFrom now on hat on man\\nFrom now on pant on man\\nman has ear is not longer actual.\\npant on man is not longer actual.\\nAfter 1 seconds:\\nAfter 2 seconds:\\nFrom now on man has ear\\nFrom now on hat on head\\nFrom now on pant on man\\nAfter 3 seconds:\\nman wearing shirt is not longer actual.\\nman has ear is not longer actual.\\nshirt on man is not longer actual.\\nhat on man is not longer actual.\\nhat on head is not longer actual.\\npant on man is not longer actual.\\nAfter 4 seconds:\\nFrom now on man has hair\\nFrom now on man sitting on toilet\\nFrom now on man wearing tie\\nFrom now on man wearing jean\\nFrom now on hair of man\\nFrom now on ear of man\\nFrom now on tie on man\\nFrom now on hand of man\\nFrom now on person wearing shirt\\nFrom now on woman has hair\\nman wearing hat is not longer actual.\\nman wearing glove is not longer actual.\\nman has arm is not longer actual.\\nman has hair is not longer actual.\\nman sitting on toilet is not longer actual.\\nman wearing tie is not longer actual.\\nhair of man is not longer actual.\\near of man is not longer actual.\\ntie on man is not longer actual.\\nhand of man is not longer actual.\\nperson wearing shirt is not longer actual.\\nwoman has hair is not longer actual.\\nAfter 5 seconds:\\nFrom now on man wearing shirt\\nFrom now on man in shirt\\nFrom now on shirt on man\\nFrom now on shirt on woman\\nFrom now on head of woman\\nFrom now on woman wearing shirt\\nFrom now on woman has hair\\nFrom now on cup on table\\nFrom now on man wearing shirt\\nFrom now on man has hair\\nFrom now on man wearing hat\\nFrom now on hand of woman\\nFrom now on arm of woman\\nman wearing shirt is not longer actual.\\nman wearing pant is not longer actual.\\nman has head is not longer actual.\\nman wearing glass is not longer actual.\\nman wearing jean is not longer actual.\\nman in shirt is not longer actual.\\nshirt on man is not longer actual.\\nshirt on woman is not longer actual.\\nhead of woman is not longer actual.\\nwoman wearing shirt is not longer actual.\\nwoman has hair is not longer actual.\\ncup on table is not longer actual.\\nman wearing shirt is not longer actual.\\nman has hair is not longer actual.\\nman wearing hat is not longer actual.\\nhand of woman is not longer actual.\\narm of woman is not longer actual.\\nAfter 6 seconds:\\nFrom now on person wearing shirt\\nFrom now on leg of woman\\nleg of woman is not longer actual.\\nAfter 7 seconds:\\nFrom now on head of woman\\nFrom now on glass on woman\\nFrom now on glass on face\\nFrom now on ear of woman\\nFrom now on person wearing short\\nFrom now on person wearing jean\\nFrom now on woman has hair\\nFrom now on woman wearing shirt\\nFrom now on hand of woman\\nFrom now on hand holding phone\\nFrom now on phone in hand\\nhead of woman is not longer actual.\\nglass on woman is not longer actual.\\nglass on face is not longer actual.\\near of woman is not longer actual.\\nperson wearing shirt is not longer actual.\\nperson wearing short is not longer actual.\\nperson wearing jean is not longer actual.\\nwoman has hair is not longer actual.\\nwoman wearing shirt is not longer actual.\\nhand of woman is not longer actual.\\nhand holding phone is not longer actual.\\nphone in hand is not longer actual.\\nThe scene ends \\n'"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['OIC_answer_without_CUID'] =  df['OIC_context'].apply(lambda x: re.sub('_[a-zA-Z0-9]*', '', x))\n",
    "df['OIC_answer_without_CUID'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T11:29:34.452293Z",
     "start_time": "2023-11-23T11:29:34.446965Z"
    }
   },
   "outputs": [],
   "source": [
    "class Substitutable(str):\n",
    "  def __new__(cls, *args, **kwargs):\n",
    "    newobj = str.__new__(cls, *args, **kwargs)\n",
    "    newobj.sub = lambda fro,to: Substitutable(re.sub(fro, to, newobj))\n",
    "    return newobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T11:29:34.503962Z",
     "start_time": "2023-11-23T11:29:34.451197Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0           man wearing shirt   man wearing hat   man ...\n1           glove on hand   man wearing pant   man wea...\n2           man wearing shirt   man has hair   man wea...\n3           woman wearing shirt   woman has hair   wom...\n4           man wearing shirt   man wearing pant   man...\n                              ...                        \n1569        handle on door   door has handle After 1 s...\n1570        woman has hair   woman wearing shirt   wom...\n1571        man wearing shirt   man wearing pant   man...\n1572        woman wearing glass   woman in shirt   wom...\n1573        man has hair   man wearing shirt   man sit...\nName: OIC_answer_without_CUID_temp, Length: 507, dtype: object"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['OIC_answer_without_CUID_temp'] = df['OIC_answer_without_CUID']\n",
    "df['OIC_answer_without_CUID_temp'] = df['OIC_answer_without_CUID_temp'].apply(lambda x: Substitutable(x).sub('\\n', ' ').sub('The scene opens:', ' ').sub('From now on', ' ').sub('is not longer actual.',' ').sub('\\nAfter [0-9]* seconds:', ' '))\n",
    "\n",
    "df['OIC_answer_without_CUID_temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T11:29:34.518517Z",
     "start_time": "2023-11-23T11:29:34.512449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          question_id                                  question video_id  \\\n0   Interaction_T1_76    Which object was thrown by the person?    XO8NL   \n1   Interaction_T1_78    Which object was opened by the person?    OY3LS   \n2  Interaction_T1_101  Which object was put down by the person?    RG0KS   \n3  Interaction_T1_137    Which object was closed by the person?    NUKJ0   \n4  Interaction_T1_171  Which object was put down by the person?    LBRYS   \n\n   start   end       answer  \\\n0    3.6  12.5  The pillow.   \n1    2.5  10.1  The laptop.   \n2   17.4  27.0     The box.   \n3   19.4  26.6    The book.   \n4    8.9  13.4    The shoe.   \n\n                                             choices  \\\n0  [{'choice_id': 0, 'choice': 'The shoe.', 'choi...   \n1  [{'choice_id': 0, 'choice': 'The laptop.', 'ch...   \n2  [{'choice_id': 0, 'choice': 'The cup/glass/bot...   \n3  [{'choice_id': 0, 'choice': 'The book.', 'choi...   \n4  [{'choice_id': 0, 'choice': 'The sandwich.', '...   \n\n                                         OIC_context  OIC_answer  \\\n0  The scene opens:\\nFrom now on man_f89c wearing...         3.0   \n1  The scene opens:\\nFrom now on glove_beed on ha...         3.0   \n2  The scene opens:\\nFrom now on man_3171 wearing...         4.0   \n3  The scene opens:\\nFrom now on woman_24bd weari...         3.0   \n4  The scene opens:\\nFrom now on man_753c wearing...         2.0   \n\n                                        OIC_question    Match  \\\n0  Which object was thrown by the person? Guess t...  Correct   \n1  Which object was opened by the person? Guess t...    Wrong   \n2  Which object was put down by the person? Guess...    Wrong   \n3  Which object was closed by the person? Guess t...    Wrong   \n4  Which object was put down by the person? Guess...    Wrong   \n\n                             OIC_answer_without_CUID  \\\n0  The scene opens:\\nFrom now on man wearing shir...   \n1  The scene opens:\\nFrom now on glove on hand\\nF...   \n2  The scene opens:\\nFrom now on man wearing shir...   \n3  The scene opens:\\nFrom now on woman wearing sh...   \n4  The scene opens:\\nFrom now on man wearing shir...   \n\n                        OIC_answer_without_CUID_temp  \n0      man wearing shirt   man wearing hat   man ...  \n1      glove on hand   man wearing pant   man wea...  \n2      man wearing shirt   man has hair   man wea...  \n3      woman wearing shirt   woman has hair   wom...  \n4      man wearing shirt   man wearing pant   man...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question_id</th>\n      <th>question</th>\n      <th>video_id</th>\n      <th>start</th>\n      <th>end</th>\n      <th>answer</th>\n      <th>choices</th>\n      <th>OIC_context</th>\n      <th>OIC_answer</th>\n      <th>OIC_question</th>\n      <th>Match</th>\n      <th>OIC_answer_without_CUID</th>\n      <th>OIC_answer_without_CUID_temp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Interaction_T1_76</td>\n      <td>Which object was thrown by the person?</td>\n      <td>XO8NL</td>\n      <td>3.6</td>\n      <td>12.5</td>\n      <td>The pillow.</td>\n      <td>[{'choice_id': 0, 'choice': 'The shoe.', 'choi...</td>\n      <td>The scene opens:\\nFrom now on man_f89c wearing...</td>\n      <td>3.0</td>\n      <td>Which object was thrown by the person? Guess t...</td>\n      <td>Correct</td>\n      <td>The scene opens:\\nFrom now on man wearing shir...</td>\n      <td>man wearing shirt   man wearing hat   man ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Interaction_T1_78</td>\n      <td>Which object was opened by the person?</td>\n      <td>OY3LS</td>\n      <td>2.5</td>\n      <td>10.1</td>\n      <td>The laptop.</td>\n      <td>[{'choice_id': 0, 'choice': 'The laptop.', 'ch...</td>\n      <td>The scene opens:\\nFrom now on glove_beed on ha...</td>\n      <td>3.0</td>\n      <td>Which object was opened by the person? Guess t...</td>\n      <td>Wrong</td>\n      <td>The scene opens:\\nFrom now on glove on hand\\nF...</td>\n      <td>glove on hand   man wearing pant   man wea...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Interaction_T1_101</td>\n      <td>Which object was put down by the person?</td>\n      <td>RG0KS</td>\n      <td>17.4</td>\n      <td>27.0</td>\n      <td>The box.</td>\n      <td>[{'choice_id': 0, 'choice': 'The cup/glass/bot...</td>\n      <td>The scene opens:\\nFrom now on man_3171 wearing...</td>\n      <td>4.0</td>\n      <td>Which object was put down by the person? Guess...</td>\n      <td>Wrong</td>\n      <td>The scene opens:\\nFrom now on man wearing shir...</td>\n      <td>man wearing shirt   man has hair   man wea...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Interaction_T1_137</td>\n      <td>Which object was closed by the person?</td>\n      <td>NUKJ0</td>\n      <td>19.4</td>\n      <td>26.6</td>\n      <td>The book.</td>\n      <td>[{'choice_id': 0, 'choice': 'The book.', 'choi...</td>\n      <td>The scene opens:\\nFrom now on woman_24bd weari...</td>\n      <td>3.0</td>\n      <td>Which object was closed by the person? Guess t...</td>\n      <td>Wrong</td>\n      <td>The scene opens:\\nFrom now on woman wearing sh...</td>\n      <td>woman wearing shirt   woman has hair   wom...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Interaction_T1_171</td>\n      <td>Which object was put down by the person?</td>\n      <td>LBRYS</td>\n      <td>8.9</td>\n      <td>13.4</td>\n      <td>The shoe.</td>\n      <td>[{'choice_id': 0, 'choice': 'The sandwich.', '...</td>\n      <td>The scene opens:\\nFrom now on man_753c wearing...</td>\n      <td>2.0</td>\n      <td>Which object was put down by the person? Guess...</td>\n      <td>Wrong</td>\n      <td>The scene opens:\\nFrom now on man wearing shir...</td>\n      <td>man wearing shirt   man wearing pant   man...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRateLimitError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[89], line 20\u001B[0m\n\u001B[1;32m     18\u001B[0m prompt \u001B[38;5;241m=\u001B[39m que_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mOIC_answer_without_CUID\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;66;03m# update column name to OIC_answer_without_CUID_temp\u001B[39;00m\n\u001B[1;32m     19\u001B[0m formatted_question \u001B[38;5;241m=\u001B[39m question\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m Guess the most likely answer among these four options: \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m+\u001B[39mchoice_string\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m Respond only with a single number between 1 and 4. If not found in the given options reply 0 not any other statements.\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m---> 20\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mrun_gpt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mformatted_question\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m     22\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(response)\u001B[38;5;241m>\u001B[39m\u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[0;32m~/Developer/IMP-OIC/gpt_ask.py:13\u001B[0m, in \u001B[0;36mrun_gpt\u001B[0;34m(context, question)\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_gpt\u001B[39m(context, question):\n\u001B[0;32m---> 13\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompletions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgpt-4\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmessages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrole\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msystem\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcontent\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontext\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m                  \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrole\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcontent\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mquestion\u001B[49m\u001B[43m}\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m                  \u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1532\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfrequency_penalty\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpresence_penalty\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m response\u001B[38;5;241m.\u001B[39mchoices[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mmessage\u001B[38;5;241m.\u001B[39mcontent\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.8/site-packages/openai/_utils/_utils.py:299\u001B[0m, in \u001B[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    297\u001B[0m             msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[38;5;241m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    298\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[0;32m--> 299\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.8/site-packages/openai/resources/chat/completions.py:598\u001B[0m, in \u001B[0;36mCompletions.create\u001B[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[1;32m    551\u001B[0m \u001B[38;5;129m@required_args\u001B[39m([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m], [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m    552\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate\u001B[39m(\n\u001B[1;32m    553\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    596\u001B[0m     timeout: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m|\u001B[39m httpx\u001B[38;5;241m.\u001B[39mTimeout \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m|\u001B[39m NotGiven \u001B[38;5;241m=\u001B[39m NOT_GIVEN,\n\u001B[1;32m    597\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ChatCompletion \u001B[38;5;241m|\u001B[39m Stream[ChatCompletionChunk]:\n\u001B[0;32m--> 598\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    599\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/chat/completions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    600\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    601\u001B[0m \u001B[43m            \u001B[49m\u001B[43m{\u001B[49m\n\u001B[1;32m    602\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmessages\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    603\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    604\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfrequency_penalty\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrequency_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    605\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfunction_call\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunction_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    606\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfunctions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunctions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    607\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogit_bias\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogit_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    608\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax_tokens\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    609\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mn\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    610\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpresence_penalty\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpresence_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    611\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mresponse_format\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    612\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mseed\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    613\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstop\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    614\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstream\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    615\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtemperature\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    616\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtool_choice\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtool_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    617\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtools\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    618\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_p\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    619\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    620\u001B[0m \u001B[43m            \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    621\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCompletionCreateParams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    622\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    623\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    624\u001B[0m \u001B[43m            \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[1;32m    625\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    626\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mChatCompletion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    627\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    628\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mStream\u001B[49m\u001B[43m[\u001B[49m\u001B[43mChatCompletionChunk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    629\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.8/site-packages/openai/_base_client.py:1063\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1049\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(\n\u001B[1;32m   1050\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1051\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1058\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1059\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[1;32m   1060\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[1;32m   1061\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[1;32m   1062\u001B[0m     )\n\u001B[0;32m-> 1063\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.8/site-packages/openai/_base_client.py:842\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m    833\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[1;32m    834\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    835\u001B[0m     cast_to: Type[ResponseT],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    840\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    841\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[0;32m--> 842\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    843\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    844\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    845\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    846\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    847\u001B[0m \u001B[43m        \u001B[49m\u001B[43mremaining_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremaining_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    848\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.8/site-packages/openai/_base_client.py:873\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m    871\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m httpx\u001B[38;5;241m.\u001B[39mHTTPStatusError \u001B[38;5;28;01mas\u001B[39;00m err:  \u001B[38;5;66;03m# thrown on 4xx and 5xx status code\u001B[39;00m\n\u001B[1;32m    872\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m retries \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_retry(err\u001B[38;5;241m.\u001B[39mresponse):\n\u001B[0;32m--> 873\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_retry_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    874\u001B[0m \u001B[43m            \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    875\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    876\u001B[0m \u001B[43m            \u001B[49m\u001B[43mretries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    877\u001B[0m \u001B[43m            \u001B[49m\u001B[43merr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    878\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    880\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    882\u001B[0m     \u001B[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001B[39;00m\n\u001B[1;32m    883\u001B[0m     \u001B[38;5;66;03m# to completion before attempting to access the response text.\u001B[39;00m\n\u001B[1;32m    884\u001B[0m     err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.8/site-packages/openai/_base_client.py:933\u001B[0m, in \u001B[0;36mSyncAPIClient._retry_request\u001B[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001B[0m\n\u001B[1;32m    929\u001B[0m \u001B[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001B[39;00m\n\u001B[1;32m    930\u001B[0m \u001B[38;5;66;03m# different thread if necessary.\u001B[39;00m\n\u001B[1;32m    931\u001B[0m time\u001B[38;5;241m.\u001B[39msleep(timeout)\n\u001B[0;32m--> 933\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    934\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    935\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    936\u001B[0m \u001B[43m    \u001B[49m\u001B[43mremaining_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremaining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    937\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    938\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    939\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.8/site-packages/openai/_base_client.py:873\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m    871\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m httpx\u001B[38;5;241m.\u001B[39mHTTPStatusError \u001B[38;5;28;01mas\u001B[39;00m err:  \u001B[38;5;66;03m# thrown on 4xx and 5xx status code\u001B[39;00m\n\u001B[1;32m    872\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m retries \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_retry(err\u001B[38;5;241m.\u001B[39mresponse):\n\u001B[0;32m--> 873\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_retry_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    874\u001B[0m \u001B[43m            \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    875\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    876\u001B[0m \u001B[43m            \u001B[49m\u001B[43mretries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    877\u001B[0m \u001B[43m            \u001B[49m\u001B[43merr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    878\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    880\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    882\u001B[0m     \u001B[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001B[39;00m\n\u001B[1;32m    883\u001B[0m     \u001B[38;5;66;03m# to completion before attempting to access the response text.\u001B[39;00m\n\u001B[1;32m    884\u001B[0m     err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.8/site-packages/openai/_base_client.py:933\u001B[0m, in \u001B[0;36mSyncAPIClient._retry_request\u001B[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001B[0m\n\u001B[1;32m    929\u001B[0m \u001B[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001B[39;00m\n\u001B[1;32m    930\u001B[0m \u001B[38;5;66;03m# different thread if necessary.\u001B[39;00m\n\u001B[1;32m    931\u001B[0m time\u001B[38;5;241m.\u001B[39msleep(timeout)\n\u001B[0;32m--> 933\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    934\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    935\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    936\u001B[0m \u001B[43m    \u001B[49m\u001B[43mremaining_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremaining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    937\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    938\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    939\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.8/site-packages/openai/_base_client.py:885\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m    882\u001B[0m     \u001B[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001B[39;00m\n\u001B[1;32m    883\u001B[0m     \u001B[38;5;66;03m# to completion before attempting to access the response text.\u001B[39;00m\n\u001B[1;32m    884\u001B[0m     err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n\u001B[0;32m--> 885\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_status_error_from_response(err\u001B[38;5;241m.\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    886\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m httpx\u001B[38;5;241m.\u001B[39mTimeoutException \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    887\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m retries \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "\u001B[0;31mRateLimitError\u001B[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "import time\n",
    "import numpy as np\n",
    "q_ids = np.unique(df['question_id'])\n",
    "print(len(q_ids))\n",
    "for q in q_ids:\n",
    "  que = df.query(\"question_id == '\"+q+\"'\")\n",
    "  question = que['question'].values[0]\n",
    "  answer = que['answer'].values[0]\n",
    "  choices = dict()\n",
    "  choice_string = ''\n",
    "  options = main.query(\"question_id == '\"+q+\"'\")[\"choices\"].values[0]\n",
    "  for choice in options:\n",
    "        choices.update({choice['choice_id']:choice['choice'].lower().strip('the').translate(str.maketrans('', '', string.punctuation)).strip()})\n",
    "        choice_string += ' ('+str(choice['choice_id']+1)+')'+str(choice['choice'].lower().strip('the').translate(str.maketrans('', '', string.punctuation)))\n",
    "  \n",
    "  que_df = df.query(\"question_id == '\"+q+\"'\")\n",
    "  prompt = que_df['OIC_answer_without_CUID'].values[0] # update column name to OIC_answer_without_CUID_temp\n",
    "  formatted_question = question+' Guess the most likely answer among these four options: '+choice_string+' Respond only with a single number between 1 and 4. If not found in the given options reply 0 not any other statements.'\n",
    "  response = run_gpt(prompt, formatted_question)\n",
    "  while True:\n",
    "    if len(response)>1:\n",
    "        response = run_gpt(prompt, formatted_question) \n",
    "    else:\n",
    "      response = int(response)\n",
    "      break\n",
    "  if int(response) > 0:\n",
    "    OIC_answer = response\n",
    "    if choices[int(OIC_answer)-1] in answer:\n",
    "      df.loc[df['question_id'] == q, 'Wo_CUID_Match'] = 'Correct' # update column name to Wo_CUID_temp\n",
    "      print(df.query(\"question_id == '\"+q+\"'\")['Wo_CUID_Match'].values[0])\n",
    "    else:\n",
    "      df.loc[df['question_id'] == q, 'Wo_CUID_Match'] = 'Wrong' # update column name to Wo_CUID_temp\n",
    "      print(df.query(\"question_id == '\"+q+\"'\")['Wo_CUID_Match'].values[0])\n",
    "  else:\n",
    "    df.loc[df['question_id'] == q, 'Wo_CUID_Match'] = 'Wrong'\n",
    "  df.to_csv('STAR_eval/new_all_cured.csv') # update column name to without_cuid_temp  \n",
    "  #df.drop(df[df['Wo_CUID_Match'].isnull().values.any()].index, inplace = True)\n",
    "  #sleep(100)\n",
    "main.head()\n",
    "main.name = 'all data'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T11:29:38.023175Z",
     "start_time": "2023-11-23T11:29:34.534407Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-23T11:29:38.021581Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T11:29:38.025224Z",
     "start_time": "2023-11-23T11:29:38.024910Z"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
